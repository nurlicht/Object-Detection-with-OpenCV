{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- The problem of rebar identification has reported *supervised* solutions, such as the one by *Zheng et al.* in [Appl. Sci. 2023,\n",
    "13, 8233](https://www.mdpi.com/2076-3417/13/14/8233).\n",
    "- Here, the Python code for an *unsupervised* approach based on a classical Laplacian-based blob-detector is presented.\n",
    "  - The detection parameters are first optimized interactively. (The default values are the final 'optimal' values).\n",
    "  - Further tweaking of parameters and the improvement of the workflow (not done here) are expected to improve the results further (but still underperforming supervised methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests opencv-python numpy matplotlib ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "\n",
    "#%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from io import BytesIO\n",
    "from ipywidgets import interact, IntSlider, widgets\n",
    "import numpy as np\n",
    "from requests import Response\n",
    "from typing import Any, Iterable\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.usercontent.google.com/download?id=1-rRbIP2ds0zSjcI8j8o1ERm3ethAAiZr&export=download&authuser=0&confirm=t&uuid=841f4a8c-ddf3-4111-aaa9-2a145f644347&at=APZUnTW0mPJm6l3LYQfxn-itAWB2:1707407066796'\n",
    "extract_path = '.'\n",
    "images_folder = 'images'\n",
    "annotations_folder = 'annotations'\n",
    "annotations_file = '100_percent_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classes (data-models and logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclass(frozen=True)\n",
    "class Annotation:\n",
    "    def __init__(self, filename: str, x1:int, y1:int, x2:int, y2:int):\n",
    "        self.filename = filename\n",
    "        self.x1 = int(x1)\n",
    "        self.y1 = int(y1)\n",
    "        self.x2 = int(x2)\n",
    "        self.y2 = int(y2)\n",
    "\n",
    "    def pt1(self):\n",
    "        return (self.x1, self.y1)\n",
    "    \n",
    "    def pt2(self):\n",
    "        return (self.x2, self.y2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse(row: list[str]):\n",
    "        filename: str = row[0].strip()\n",
    "        xy: list[str] = row[1].split(' ')\n",
    "        return Annotation(\n",
    "            filename = filename,\n",
    "            x1=int(xy[0].strip()), \n",
    "            y1=int(xy[1].strip()), \n",
    "            x2=int(xy[2].strip()), \n",
    "            y2=int(xy[3].strip()), \n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def from_keypoint(keypoint: cv2.KeyPoint, filename: str = ''):\n",
    "        half_width: int = keypoint.size / 2\n",
    "        return Annotation(\n",
    "            filename=filename,\n",
    "            x1=keypoint.pt[0] - half_width,\n",
    "            y1=keypoint.pt[1] - half_width,\n",
    "            x2=keypoint.pt[0] + half_width,\n",
    "            y2=keypoint.pt[1] + half_width\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def get_image_annotations(annotations: list, filename: str) -> list:\n",
    "        return list(filter(lambda annotation: annotation.filename == filename, annotations))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_indices_of_images_with_annotations(annotations: list, filenames: list[str]) -> list[int]:\n",
    "        has_annotation = lambda i: len(Annotation.get_image_annotations(annotations, filenames[i])) > 0\n",
    "        return list(filter(has_annotation, range(0, len(filenames))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected execution time (if dataset not downloaded yet): < 4 minutes\n",
    "def download_dataset(url: str, extract_path: str, images_folder: str) -> None:\n",
    "    if os.path.exists(images_folder):\n",
    "        return\n",
    "    response: Response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with ZipFile(BytesIO(response.content), 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "download_dataset(url=url, extract_path=extract_path, images_folder=images_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images and file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected execution time: < 2 minutes\n",
    "filenames: list[str] = os.listdir(images_folder)\n",
    "images: list[cv2.typing.MatLike] = [cv2.imread(os.path.join(images_folder, filename)) for filename in filenames]\n",
    "\n",
    "print(f\"images: {len(images)}, filenames: {len(filenames)}\")\n",
    "assert len(filenames) == 2125\n",
    "assert len(images) == len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path) -> list[Annotation]:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [Annotation.parse(row) for row in csv.reader(file)]\n",
    "\n",
    "annotations_path: str = os.path.join(annotations_folder, annotations_file)\n",
    "annotations: list[Annotation] = load_csv(annotations_path)\n",
    "\n",
    "print(f\"images: {len(images)}, annotations: {len(annotations)}\")\n",
    "assert len(images) == 2125\n",
    "assert len(annotations) == 179713"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify images without annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected execution time: 15 seconds\n",
    "indices_of_images_with_annotations: list[int] = Annotation.get_indices_of_images_with_annotations(annotations, filenames)\n",
    "\n",
    "print(f\"images: {len(images)}, images with annotations: {len(indices_of_images_with_annotations)}\")\n",
    "assert len(images) == 2125\n",
    "assert len(indices_of_images_with_annotations) == 1125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browse images and display their *<span style='color:green'>known</span>* bounding-boxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_index: int):\n",
    "    if (image_index < 0 or image_index > len(images)):\n",
    "        return\n",
    "    image_annotations: list[Annotation] = Annotation.get_image_annotations(annotations, filenames[image_index])\n",
    "    img = images[image_index].copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    [cv2.rectangle(img=img, pt1=annotation.pt1(), pt2=annotation.pt2(), color=(0, 255, 0), thickness=4) for annotation in image_annotations]\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"file name: {filenames[image_index]}, annotations = {len(image_annotations)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_image_with_widgets():\n",
    "    image_index_slider = IntSlider(min=0, max=len(images) - 1, step=1, value=0)\n",
    "    image_index_textbox = widgets.IntText(value=0, description='Image Index:', continuous_update=False)\n",
    "\n",
    "    image_index_textbox.observe(lambda change: setattr(image_index_slider, 'value', change.new), names='value')\n",
    "    image_index_slider.observe(lambda change: setattr(image_index_textbox, 'value', change.new), names='value')\n",
    "\n",
    "    interact(show_image, image_index=image_index_slider)\n",
    "    display(image_index_textbox)\n",
    "\n",
    "show_image_with_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclass(frozen=True)\n",
    "class AnnotationList:\n",
    "    def __init__(self, items: list[Annotation], filename: str):\n",
    "        self.items = items\n",
    "        self.filename = filename\n",
    "\n",
    "class Detector(ABC):\n",
    "    # Batch processing\n",
    "    def detect(self, images: list[cv2.typing.MatLike], filenames: list[str], indices: list[int], params: dict[str, Any]) -> list[AnnotationList]:\n",
    "        progress_fixed_string: str = ' out of ' + str(len(indices))\n",
    "        return [AnnotationList(\n",
    "            self.detect_single_complete(images[j], filenames[j], params | {'filename': filenames[j]}, str(i + 1) + progress_fixed_string),\n",
    "            filenames[i]\n",
    "        ) for i, j in enumerate(indices)]\n",
    "\n",
    "    # Handling the logic for the separation of single-image and batch processing\n",
    "    def detect_single_complete(self, image: cv2.typing.MatLike, filename: str, params: dict[str, Any], progress: str = None) -> list[Annotation]:\n",
    "        if (progress != None):\n",
    "            print('\\r' + progress, end='')\n",
    "        image_params = Detector.image_params(filename, params)\n",
    "        annotations: list[Annotation] = self.detect_single(image, image_params)\n",
    "        return [Annotation(filename, ann.x1, ann.y1, ann.x2, ann.y2) for ann in annotations]\n",
    "\n",
    "    # Single-image processing\n",
    "    @abstractmethod\n",
    "    def detect_single(self, image: cv2.typing.MatLike, image_params: dict[str, Any]) -> list[Annotation]:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def image_params(filename: str, params: dict[str, Any]) -> dict[str, Any]:\n",
    "        params['rebar_size'] = int(filename[:-6][-2:]) # rebar_119_16MM.jpg -> 16\n",
    "        return params\n",
    "\n",
    "\n",
    "class SimpleBlobDetector(Detector):\n",
    "    def detect_single(self, image: cv2.typing.MatLike, image_params: dict[str, Any]) -> list[Annotation]:\n",
    "        cv_params = SimpleBlobDetector.get_cv_parameters(image_params)\n",
    "        cv_detector = cv2.SimpleBlobDetector_create(cv_params)\n",
    "        keypoints: cv2.KeyPoint = cv_detector.detect(image)\n",
    "        return list(map(Annotation.from_keypoint, keypoints))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cv_parameters(image_params: dict[str, Any]) -> Any:\n",
    "        #size: float = float(image_params['rebar_size'])\n",
    "        #print(image_params)\n",
    "\n",
    "        cv_params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "        cv_params.minThreshold = float(image_params['min_int'])\n",
    "        cv_params.maxThreshold = float(image_params['max_int'])\n",
    "\n",
    "        cv_params.filterByArea = True\n",
    "        cv_params.minArea = float(image_params['min_size'] ** 2)\n",
    "        cv_params.maxArea = float(image_params['max_size'] ** 2)\n",
    "\n",
    "        cv_params.filterByCircularity = True\n",
    "        cv_params.minCircularity = 0.001\n",
    "        cv_params.maxCircularity = 1.00\n",
    "\n",
    "        cv_params.filterByConvexity = True\n",
    "        cv_params.minConvexity = 0.001\n",
    "        cv_params.maxConvexity = 1.00\n",
    "\n",
    "        cv_params.filterByInertia = True\n",
    "        cv_params.minInertiaRatio = 0.001\n",
    "        cv_params.maxInertiaRatio = 1.00\n",
    "\n",
    "        return cv_params        \n",
    "\n",
    "simple_blob_detector: Detector = SimpleBlobDetector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browse images and display their *<span style='color:yellow'>estimated</span>* bounding-boxes (try & error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For try and error and parameter optimization\n",
    "def show_image(\n",
    "        image_index: int,\n",
    "        min_size: int,\n",
    "        max_size: int,\n",
    "        min_int: int,\n",
    "        max_int: int,\n",
    "        connected_component_threshold: int,\n",
    "        connected_component_connectivity: int,\n",
    "        gaussian_size: int,\n",
    "        median_size: int,\n",
    "        min_canny: int,\n",
    "        max_canny: int,\n",
    "        laplaceian_ksize: int,\n",
    "        bilateral_d: int,\n",
    "        bilateral_sigma: int,\n",
    "    ):\n",
    "    if (image_index < 0 or image_index > len(images)):\n",
    "        return\n",
    "    if (image_index not in indices_of_images_with_annotations):\n",
    "        print(image_index)\n",
    "        print(filenames[image_index])\n",
    "        img = np.zeros(images[image_index].shape)\n",
    "        plt.imshow(img)\n",
    "        return\n",
    "\n",
    "    params: dict[str, int] = {\n",
    "        'min_size': min_size,\n",
    "        'max_size': max_size,\n",
    "        'min_int': min_int,\n",
    "        'max_int': max_int\n",
    "    }\n",
    "    #image_annotations: list[Annotation] = Annotation.get_image_annotations(annotations, filenames[image_index])\n",
    "    #img = images[image_index].copy()\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #[cv2.rectangle(img=img, pt1=annotation.pt1(), pt2=annotation.pt2(), color=(0, 255, 0), thickness=4) for annotation in image_annotations]\n",
    "    \n",
    "    img = images[image_index].copy()\n",
    "    #img = np.float32(img)\n",
    "    #img = cv2.bilateralFilter(img, bilateral_d, sigmaColor=bilateral_sigma, sigmaSpace=bilateral_sigma)\n",
    "    img = cv2.GaussianBlur(img, (gaussian_size, gaussian_size), sigmaX=0, sigmaY=0)\n",
    "    img = cv2.medianBlur(img, ksize=median_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, (gaussian_size, gaussian_size), sigmaX=0, sigmaY=0)\n",
    "    img = cv2.medianBlur(img, ksize=median_size)\n",
    "    img = cv2.Laplacian(img, ddepth=cv2.CV_16S, ksize=laplaceian_ksize)\n",
    "    img = cv2.convertScaleAbs(img)\n",
    "    img = cv2.medianBlur(img, ksize=median_size)\n",
    "    img = cv2.convertScaleAbs(img)\n",
    "    #img = cv2.Canny(img, threshold1=min_canny, threshold2=max_canny)\n",
    "    #img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    #result = cv2.connectedComponentsWithStats(img, connected_component_connectivity, cv2.CV_32S)\n",
    "    #(num_labels, labels, stats, centroids) = result\n",
    "    #print(num_labels)\n",
    "    #print(labels)\n",
    "    #print(stats)\n",
    "    #print(centroids)\n",
    "    #img = abs(255 - img) \n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #img = cv2.GaussianBlur(img, (max_size, max_size), sigmaX=0, sigmaY=0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    detected_annotations: list[Annotation] = simple_blob_detector.detect_single_complete(img, filenames[image_index], params)\n",
    "    [cv2.rectangle(img=img, pt1=annotation.pt1(), pt2=annotation.pt2(), color=(0, 255, 255), thickness=10) for annotation in detected_annotations]\n",
    "\n",
    "    #img_gray = cv2.cvtColor(images[image_index], cv2.COLOR_BGR2GRAY)\n",
    "    #detected_annotations: list[Annotation] = detectors[0].detect_single_complete(img_gray, filenames[image_index], params)\n",
    "    #[cv2.rectangle(img=img_gray, pt1=annotation.pt1(), pt2=annotation.pt2(), color=(255, 255, 255), thickness=10) for annotation in detected_annotations]\n",
    "\n",
    "\n",
    "    #plt.imshow(img, cmap='gray')\n",
    "    plt.imshow(img)\n",
    "    #plt.title(f\"file name: {filenames[image_index]}, annotations = {len(detected_annotations)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_image_with_widgets():\n",
    "    bilateral_d_slider = IntSlider(min=1, max=200, step=1, value=1)\n",
    "    bilateral_sigma_slider = IntSlider(min=1, max=200, step=1, value=5)\n",
    "    connected_component_threshold_slider = IntSlider(min=1, max=255, step=1, value=5)\n",
    "    connected_component_connectivity_slider = IntSlider(min=4, max=8, step=4, value=4)\n",
    "    gaussian_size_slider = IntSlider(min=1, max=19, step=2, value=17)\n",
    "    median_size_slider = IntSlider(min=1, max=19, step=2, value=19)\n",
    "    min_canny_slider = IntSlider(min=1, max=13, step=2, value=7)\n",
    "    max_canny_slider = IntSlider(min=1, max=255, step=1, value=200)\n",
    "    laplaceian_ksize_slider = IntSlider(min=1, max=15, step=1, value=7)\n",
    "    min_size_slider = IntSlider(min=1, max=300, step=1, value=72)\n",
    "    max_size_slider = IntSlider(min=1, max=300, step=1, value=100)\n",
    "    min_int_slider = IntSlider(min=1, max=100, step=1, value=1)\n",
    "    max_int_slider = IntSlider(min=1, max=255, step=1, value=189)\n",
    "\n",
    "    image_index_slider = IntSlider(min=0, max=len(images) - 1, step=1, value=0)\n",
    "    image_index_textbox = widgets.IntText(value=0, description='Image Index:', continuous_update=False)\n",
    "\n",
    "    image_index_textbox.observe(lambda change: setattr(image_index_slider, 'value', change.new), names='value')\n",
    "    image_index_slider.observe(lambda change: setattr(image_index_textbox, 'value', change.new), names='value')\n",
    "\n",
    "    interact(\n",
    "        show_image,\n",
    "        image_index=image_index_slider,\n",
    "        min_size=min_size_slider,\n",
    "        max_size=max_size_slider,\n",
    "        min_int=min_int_slider,\n",
    "        max_int=max_int_slider,\n",
    "        connected_component_threshold=connected_component_threshold_slider,\n",
    "        connected_component_connectivity=connected_component_connectivity_slider,\n",
    "        gaussian_size=gaussian_size_slider,\n",
    "        median_size=median_size_slider,\n",
    "        min_canny=min_canny_slider,\n",
    "        max_canny=max_canny_slider,\n",
    "        laplaceian_ksize = laplaceian_ksize_slider,\n",
    "        bilateral_d=bilateral_d_slider,\n",
    "        bilateral_sigma=bilateral_sigma_slider,\n",
    "    )\n",
    "    display(image_index_textbox)\n",
    "\n",
    "show_image_with_widgets() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimized (Laplace) detctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceDetector(Detector):\n",
    "    def __init__(self, simple_blob_detector):\n",
    "        self.simple_blob_detector = simple_blob_detector\n",
    "\n",
    "    def detect_single(self, image: cv2.typing.MatLike, image_params: dict[str, Any]) -> list[Annotation]:\n",
    "        filename: str = image_params['filename']\n",
    "\n",
    "        simple_blob_detector_params: dict[str, Any] = image_params['simple_blob_detector_params']\n",
    "\n",
    "        gaussian_size: int = image_params['gaussian_size']\n",
    "        median_size: int = image_params['median_size']\n",
    "        laplaceian_ksize: int = image_params['laplaceian_ksize']\n",
    "\n",
    "        img = image.copy()\n",
    "        img = cv2.GaussianBlur(img, (gaussian_size, gaussian_size), sigmaX=0, sigmaY=0)\n",
    "        img = cv2.medianBlur(img, ksize=median_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.GaussianBlur(img, (gaussian_size, gaussian_size), sigmaX=0, sigmaY=0)\n",
    "        img = cv2.medianBlur(img, ksize=median_size)\n",
    "        img = cv2.Laplacian(img, ddepth=cv2.CV_16S, ksize=laplaceian_ksize)\n",
    "        img = cv2.convertScaleAbs(img)\n",
    "        img = cv2.medianBlur(img, ksize=median_size)\n",
    "        img = cv2.convertScaleAbs(img)\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        detected_annotations: list[Annotation] = self.simple_blob_detector.detect_single_complete(img, filename, simple_blob_detector_params)\n",
    "        \n",
    "        return detected_annotations\n",
    "    \n",
    "laplace_detectror: Detector = LaplaceDetector(simple_blob_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare detected annotations with known ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected execution time: 12 minutes\n",
    "class Validator:\n",
    "    @staticmethod\n",
    "    def validate(\n",
    "        images: list[cv2.typing.MatLike],\n",
    "        filenames: list[str],\n",
    "        expected_annotations: list[AnnotationList],\n",
    "        indices_of_images_with_annotations: list[int],\n",
    "        params: dict[str, Any]\n",
    "    ) -> dict[str, float | int]:\n",
    "        print('processing ' + str(len(indices_of_images_with_annotations)) + ' images started.')\n",
    "        calculated_annotations: list[AnnotationList] = laplace_detectror.detect(images, filenames, indices_of_images_with_annotations, params)\n",
    "        print('')\n",
    "        print('processing ' + str(len(indices_of_images_with_annotations)) + ' images ended.')\n",
    "        calculated_annotations_count = len(calculated_annotations)\n",
    "        error_mean: float = Validator.annotation_count_error(calculated_annotations, expected_annotations)\n",
    "        return {'error_mean': error_mean, 'calculated_annotations_count': calculated_annotations_count}\n",
    "\n",
    "    @staticmethod\n",
    "    def annotation_count_error(calculated: list[AnnotationList], expected: list[AnnotationList]) -> float:\n",
    "        assert(len(calculated) == len(expected))\n",
    "        error_list: Iterable[float] = map(lambda i : abs( 1 - len(calculated[i].items) / len(expected[i].items)), range(len(expected)))\n",
    "        error_mean: float = np.array(list(error_list)).mean()\n",
    "        return error_mean\n",
    "    \n",
    "class App:\n",
    "    @staticmethod\n",
    "    def run():\n",
    "        simple_blob_detector_params: dict[str, Any] = {\n",
    "            'min_size': 72,\n",
    "            'max_size': 100,\n",
    "            'min_int': 1,\n",
    "            'max_int': 189\n",
    "        }\n",
    "        laplace_detectror_params: dict[str, Any] = {\n",
    "            'simple_blob_detector_params': simple_blob_detector_params,\n",
    "            'gaussian_size': 17,\n",
    "            'median_size': 19,\n",
    "            'laplaceian_ksize': 7,\n",
    "        }\n",
    "        expected_annotations: list[AnnotationList] = [\n",
    "            AnnotationList(Annotation.get_image_annotations(annotations, filenames[i]), filenames[i])\n",
    "            for i in indices_of_images_with_annotations\n",
    "        ]\n",
    "        assert (len(expected_annotations) == 1125)\n",
    "\n",
    "        results: dict[str, float | int] = Validator.validate(images, filenames, expected_annotations, indices_of_images_with_annotations, laplace_detectror_params)\n",
    "        print(results)\n",
    "        assert(results['error_mean'] < 0.65) # 0.6406604616379477\n",
    "\n",
    "\n",
    "App.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
